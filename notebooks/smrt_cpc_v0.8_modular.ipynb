{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0fe52ef-a308-4ff5-9f17-a93faf23df29",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0accf8b-9ab6-4ef7-932d-f1cdc04a222e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2d5403d-2b9c-4627-8c60-a7dd241743ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30568b95-93f0-4adf-b091-67274e9fae37",
   "metadata": {},
   "source": [
    "## Load local module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65096da3-e095-412c-a7dd-5c67d58f0020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(\"/dcai/users/chache/smrt-foundation\")\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "device=torch.device('cuda')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00d55fc-4ed8-45b9-a84a-d71adc8ab250",
   "metadata": {},
   "source": [
    "## Optional copy step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1a560f2-68ce-4e7f-bf15-aa5ea0e0b00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16G\t../data/01_processed/ssl_sets/ob007_test.memmap/\n",
      "'./shard_00028.npy' -> '/tmp/shard_00028.npy'\n",
      "'./shard_00021.npy' -> '/tmp/shard_00021.npy'\n",
      "'./shard_00026.npy' -> '/tmp/shard_00026.npy'\n",
      "'./shard_00013.npy' -> '/tmp/shard_00013.npy'\n",
      "'./shard_00014.npy' -> '/tmp/shard_00014.npy'\n",
      "'./shard_00005.npy' -> '/tmp/shard_00005.npy'\n",
      "'./shard_00002.npy' -> '/tmp/shard_00002.npy'\n",
      "'./shard_00030.npy' -> '/tmp/shard_00030.npy'\n",
      "'./shard_00015.npy' -> '/tmp/shard_00015.npy'\n",
      "'./shard_00012.npy' -> '/tmp/shard_00012.npy'\n",
      "'./shard_00027.npy' -> '/tmp/shard_00027.npy'\n",
      "'./shard_00020.npy' -> '/tmp/shard_00020.npy'\n",
      "'./shard_00029.npy' -> '/tmp/shard_00029.npy'\n",
      "'./shard_00031.npy' -> '/tmp/shard_00031.npy'\n",
      "'./shard_00003.npy' -> '/tmp/shard_00003.npy'\n",
      "'./shard_00004.npy' -> '/tmp/shard_00004.npy'\n",
      "'./shard_00007.npy' -> '/tmp/shard_00007.npy'\n",
      "'./shard_00000.npy' -> '/tmp/shard_00000.npy'\n",
      "'./shard_00009.npy' -> '/tmp/shard_00009.npy'\n",
      "'./shard_00018.npy' -> '/tmp/shard_00018.npy'\n",
      "'./shard_00011.npy' -> '/tmp/shard_00011.npy'\n",
      "'./shard_00016.npy' -> '/tmp/shard_00016.npy'\n",
      "'./shard_00023.npy' -> '/tmp/shard_00023.npy'\n",
      "'./shard_00024.npy' -> '/tmp/shard_00024.npy'\n",
      "'./shard_00008.npy' -> '/tmp/shard_00008.npy'\n",
      "'./shard_00001.npy' -> '/tmp/shard_00001.npy'\n",
      "'./shard_00006.npy' -> '/tmp/shard_00006.npy'\n",
      "'./shard_00025.npy' -> '/tmp/shard_00025.npy'\n",
      "'./shard_00022.npy' -> '/tmp/shard_00022.npy'\n",
      "'./shard_00017.npy' -> '/tmp/shard_00017.npy'\n",
      "'./shard_00010.npy' -> '/tmp/shard_00010.npy'\n",
      "'./shard_00019.npy' -> '/tmp/shard_00019.npy'\n",
      "\n",
      "real\t0m0.868s\n",
      "user\t0m0.049s\n",
      "sys\t0m12.308s\n",
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "tmpfs          1008G   16G  993G   2% /tmp\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! du -h ../data/01_processed/ssl_sets/ob007_test.memmap/\n",
    "! cd ../data/01_processed/ssl_sets/ob007_test.memmap/ && time find  -type f -name '*.npy' | xargs -P16 -IX cp -v X $TMPDIR/ \n",
    "! df -h ${TMPDIR:-/tmp}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35721f8-49e5-4530-af0c-56c1592881ac",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d5594d9-8412-41c9-8e30-1f5855ad109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smrt_foundation.dataset import ShardedMemmapDataset\n",
    "B = 64\n",
    "# ssl_ds = ShardedMemmapDataset(\"../data/01_processed/ssl_sets/ob007_test.memmap/\")\n",
    "ssl_ds = ShardedMemmapDataset(\"/tmp\")\n",
    "ssl_dl = DataLoader(ssl_ds, batch_size=B, num_workers=8, pin_memory=True, prefetch_factor=4, shuffle=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61673259-d529-46d2-b571-a8e961e13312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -0.6270,  0.7300,  0.0000],\n",
       "        [ 1.0000,  0.3848,  1.5146,  0.0000],\n",
       "        [ 0.0000,  0.0280, -1.6045,  0.0000],\n",
       "        [ 1.0000,  0.6685, -0.2966,  0.0000],\n",
       "        [ 1.0000,  0.2917, -1.6045,  0.0000],\n",
       "        [ 0.0000,  0.2917, -1.1924,  0.0000],\n",
       "        [ 1.0000,  2.4863, -0.5542,  0.0000],\n",
       "        [ 0.0000,  2.1367,  0.4128,  0.0000],\n",
       "        [ 0.0000, -0.0933, -0.8486,  0.0000],\n",
       "        [ 0.0000,  0.0849,  0.3252,  0.0000]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(ssl_dl))\n",
    "batch[0,0:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2b85779-3d4c-4f2b-8629-6c42e22f4ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7976/7976 [00:14<00:00, 559.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# for batch in tqdm(ssl_dl):\n",
    "#     x=batch.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fb7356-c964-4582-aab9-1058776ba962",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67b1c29a-16f5-4aad-b7bd-b14ac1e088da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable parameters: 2.08m\n"
     ]
    }
   ],
   "source": [
    "from smrt_foundation.model import Smrt2Vec\n",
    "from smrt_foundation.loss import InfoNCE\n",
    "model = Smrt2Vec().to(device)\n",
    "model.train()\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"trainable parameters: {round(total_params/1e6,2)}m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bce11e6-a0dd-4f03-be50-48bfd51acdbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.7258, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = InfoNCE()\n",
    "c_proj, targets, mask = model(batch.to(device))\n",
    "loss(c_proj, targets, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda94886-4b85-4265-8c26-382885dc8704",
   "metadata": {},
   "source": [
    "# Pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf3b37aa-90b9-459d-9b22-5c82f20e802b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Feb  6 10:10:43 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.126.09             Driver Version: 580.126.09     CUDA Version: 13.1     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA H100 80GB HBM3          On  |   00000000:1B:00.0 Off |                    0 |\n",
      "| N/A   32C    P0            127W /  700W |    7773MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA H100 80GB HBM3          On  |   00000000:43:00.0 Off |                    0 |\n",
      "| N/A   31C    P0             70W /  700W |       4MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA H100 80GB HBM3          On  |   00000000:52:00.0 Off |                    0 |\n",
      "| N/A   33C    P0             69W /  700W |       4MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA H100 80GB HBM3          On  |   00000000:61:00.0 Off |                    0 |\n",
      "| N/A   32C    P0             73W /  700W |       4MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   4  NVIDIA H100 80GB HBM3          On  |   00000000:9D:00.0 Off |                    0 |\n",
      "| N/A   30C    P0             69W /  700W |       4MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   5  NVIDIA H100 80GB HBM3          On  |   00000000:C3:00.0 Off |                    0 |\n",
      "| N/A   29C    P0             70W /  700W |       4MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   6  NVIDIA H100 80GB HBM3          On  |   00000000:D1:00.0 Off |                    0 |\n",
      "| N/A   32C    P0             69W /  700W |       4MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   7  NVIDIA H100 80GB HBM3          On  |   00000000:DF:00.0 Off |                    0 |\n",
      "| N/A   33C    P0             70W /  700W |       4MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A          596156      C   /usr/bin/python                        7764MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ee6ec80-8ce8-4258-acae-72e849b0a74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if torch.cuda.device_count() > 1:\n",
    "#    print(f\"Using {torch.cuda.device_count()} GPUs via DataParallel\")\n",
    "#    model = nn.DataParallel(Smrt2Vec())\n",
    "#    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "664fb7e8-b12a-4ad3-be30-151b91e00419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4: 100%|██████████| 7976/7976 [06:31<00:00, 20.35it/s, loss=3.8523, lr=0.000537]\n",
      "Epoch 2/4: 100%|██████████| 7976/7976 [06:29<00:00, 20.48it/s, loss=3.3509, lr=0.000325]\n",
      "Epoch 3/4: 100%|██████████| 7976/7976 [06:29<00:00, 20.49it/s, loss=4.4448, lr=0.000097]\n",
      "Epoch 4/4: 100%|██████████| 7976/7976 [06:29<00:00, 20.49it/s, loss=5.5813, lr=0.000000]\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.02)\n",
    "criterion = InfoNCE(temperature=0.1).to(device)\n",
    "EPOCHS = 4\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=6e-4,\n",
    "    total_steps=len(ssl_dl) * EPOCHS,\n",
    "    pct_start=0.05\n",
    ")\n",
    "    \n",
    "model.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    progress_bar = tqdm(ssl_dl, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "\n",
    "    for i, batch in enumerate(progress_bar):\n",
    "        batch = batch.to(device, non_blocking=True)\n",
    "\n",
    "        with torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "            c_proj, targets, mask_idx = model(batch)\n",
    "            loss = criterion(c_proj, targets, mask_idx)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            progress_bar.set_postfix(\n",
    "                loss=f\"{loss.item():.4f}\",\n",
    "                lr=f\"{scheduler.get_last_lr()[0]:.6f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdfe6610-83a1-4ef8-877c-baff1c481044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), '../models/smrt2vec_8epoch.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e135487c-f327-4650-a52a-2327239962c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smrt_foundation.dataset import LegacyMethylDataset, compute_log_normalization_stats\n",
    "import polars as pl\n",
    "TRAIN_PATH = '../data/01_processed/val_sets/pacbio_standard_train.parquet'\n",
    "VAL_PATH =  '../data/01_processed/val_sets/pacbio_standard_test.parquet'\n",
    "KINETICS_FEATURES = ['fi', 'fp', 'ri', 'rp']\n",
    "\n",
    "df = pl.read_parquet(TRAIN_PATH).head(1_000_000)\n",
    "train_means, train_stds = compute_log_normalization_stats(df, KINETICS_FEATURES)\n",
    "\n",
    "methyl_train_ds = LegacyMethylDataset(TRAIN_PATH, train_means, train_stds, context=32, restrict_row_groups=5)\n",
    "methyl_train_dl = DataLoader(methyl_train_ds,\n",
    "                             # num_workers=8,\n",
    "                             batch_size=256,\n",
    "                             drop_last=True,\n",
    "                             persistent_workers=False,\n",
    "                             # prefetch_factor=5\n",
    "                            )\n",
    "\n",
    "methyl_val_ds = LegacyMethylDataset(VAL_PATH,\n",
    "                                      means=train_means,\n",
    "                                      stds=train_stds,\n",
    "                                      context=32,\n",
    "                                      restrict_row_groups=5)\n",
    "methyl_val_dl = DataLoader(methyl_val_ds,\n",
    "                        batch_size=256,\n",
    "                        drop_last=True,\n",
    "                        persistent_workers=False,\n",
    "                        prefetch_factor=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59aefd3f-eeac-47d6-9ab5-13af7dd648e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>read_name</th><th>cg_pos</th><th>seq</th><th>qual</th><th>np</th><th>fi</th><th>fp</th><th>ri</th><th>rp</th><th>label</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>list[u8]</td><td>u8</td><td>list[u16]</td><td>list[u16]</td><td>list[u16]</td><td>list[u16]</td><td>i32</td></tr></thead><tbody><tr><td>&quot;m64168_200820_000733/48169889/…</td><td>3058</td><td>&quot;GATGTCCTGGGGATTCGGGGGCATAACTGC…</td><td>[60, 67, … 69]</td><td>8</td><td>[15, 29, … 35]</td><td>[7, 19, … 23]</td><td>[10, 10, … 5]</td><td>[34, 39, … 33]</td><td>0</td></tr><tr><td>&quot;m64168_200820_000733/45943110/…</td><td>8167</td><td>&quot;TCTCCACGTTGGCCACGCTGGTCTCGAACT…</td><td>[93, 73, … 93]</td><td>13</td><td>[33, 18, … 26]</td><td>[20, 46, … 27]</td><td>[48, 70, … 20]</td><td>[20, 16, … 51]</td><td>0</td></tr><tr><td>&quot;m64168_200823_191315/50332760/…</td><td>1413</td><td>&quot;AATTTCTTGAAGAGACGAAAGTCTGTGGGT…</td><td>[93, 93, … 93]</td><td>32</td><td>[32, 12, … 18]</td><td>[21, 9, … 13]</td><td>[16, 17, … 13]</td><td>[16, 23, … 22]</td><td>1</td></tr><tr><td>&quot;m64168_200823_191315/177537981…</td><td>4708</td><td>&quot;CAACCCACTGCCAAGCGCTTCCTGCCACCT…</td><td>[93, 82, … 93]</td><td>9</td><td>[13, 19, … 19]</td><td>[23, 14, … 34]</td><td>[9, 21, … 31]</td><td>[21, 13, … 34]</td><td>1</td></tr><tr><td>&quot;m64168_200823_191315/49154585/…</td><td>5695</td><td>&quot;CCTCCCTACCGAAAACGGGGATCGTGTGAA…</td><td>[13, 58, … 53]</td><td>3</td><td>[6, 35, … 10]</td><td>[12, 34, … 19]</td><td>[17, 13, … 20]</td><td>[24, 12, … 43]</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 10)\n",
       "┌────────────┬────────┬────────────┬────────────┬───┬────────────┬────────────┬────────────┬───────┐\n",
       "│ read_name  ┆ cg_pos ┆ seq        ┆ qual       ┆ … ┆ fp         ┆ ri         ┆ rp         ┆ label │\n",
       "│ ---        ┆ ---    ┆ ---        ┆ ---        ┆   ┆ ---        ┆ ---        ┆ ---        ┆ ---   │\n",
       "│ str        ┆ i64    ┆ str        ┆ list[u8]   ┆   ┆ list[u16]  ┆ list[u16]  ┆ list[u16]  ┆ i32   │\n",
       "╞════════════╪════════╪════════════╪════════════╪═══╪════════════╪════════════╪════════════╪═══════╡\n",
       "│ m64168_200 ┆ 3058   ┆ GATGTCCTGG ┆ [60, 67, … ┆ … ┆ [7, 19, …  ┆ [10, 10, … ┆ [34, 39, … ┆ 0     │\n",
       "│ 820_000733 ┆        ┆ GGATTCGGGG ┆ 69]        ┆   ┆ 23]        ┆ 5]         ┆ 33]        ┆       │\n",
       "│ /48169889/ ┆        ┆ GCATAACTGC ┆            ┆   ┆            ┆            ┆            ┆       │\n",
       "│ …          ┆        ┆ …          ┆            ┆   ┆            ┆            ┆            ┆       │\n",
       "│ m64168_200 ┆ 8167   ┆ TCTCCACGTT ┆ [93, 73, … ┆ … ┆ [20, 46, … ┆ [48, 70, … ┆ [20, 16, … ┆ 0     │\n",
       "│ 820_000733 ┆        ┆ GGCCACGCTG ┆ 93]        ┆   ┆ 27]        ┆ 20]        ┆ 51]        ┆       │\n",
       "│ /45943110/ ┆        ┆ GTCTCGAACT ┆            ┆   ┆            ┆            ┆            ┆       │\n",
       "│ …          ┆        ┆ …          ┆            ┆   ┆            ┆            ┆            ┆       │\n",
       "│ m64168_200 ┆ 1413   ┆ AATTTCTTGA ┆ [93, 93, … ┆ … ┆ [21, 9, …  ┆ [16, 17, … ┆ [16, 23, … ┆ 1     │\n",
       "│ 823_191315 ┆        ┆ AGAGACGAAA ┆ 93]        ┆   ┆ 13]        ┆ 13]        ┆ 22]        ┆       │\n",
       "│ /50332760/ ┆        ┆ GTCTGTGGGT ┆            ┆   ┆            ┆            ┆            ┆       │\n",
       "│ …          ┆        ┆ …          ┆            ┆   ┆            ┆            ┆            ┆       │\n",
       "│ m64168_200 ┆ 4708   ┆ CAACCCACTG ┆ [93, 82, … ┆ … ┆ [23, 14, … ┆ [9, 21, …  ┆ [21, 13, … ┆ 1     │\n",
       "│ 823_191315 ┆        ┆ CCAAGCGCTT ┆ 93]        ┆   ┆ 34]        ┆ 31]        ┆ 34]        ┆       │\n",
       "│ /177537981 ┆        ┆ CCTGCCACCT ┆            ┆   ┆            ┆            ┆            ┆       │\n",
       "│ …          ┆        ┆ …          ┆            ┆   ┆            ┆            ┆            ┆       │\n",
       "│ m64168_200 ┆ 5695   ┆ CCTCCCTACC ┆ [13, 58, … ┆ … ┆ [12, 34, … ┆ [17, 13, … ┆ [24, 12, … ┆ 1     │\n",
       "│ 823_191315 ┆        ┆ GAAAACGGGG ┆ 53]        ┆   ┆ 19]        ┆ 20]        ┆ 43]        ┆       │\n",
       "│ /49154585/ ┆        ┆ ATCGTGTGAA ┆            ┆   ┆            ┆            ┆            ┆       │\n",
       "│ …          ┆        ┆ …          ┆            ┆   ┆            ┆            ┆            ┆       │\n",
       "└────────────┴────────┴────────────┴────────────┴───┴────────────┴────────────┴────────────┴───────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b7ce833-3e47-4b97-b177-6913c9ef37c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5129 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'torch.dtype' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m probe.train()\n\u001b[32m     22\u001b[39m running_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethyl_train_dl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlabel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:740\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    737\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    738\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m740\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    741\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    743\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    744\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    745\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    746\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:800\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    798\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    799\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    801\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    802\u001b[39m         data = _utils.pin_memory.pin_memory(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py:33\u001b[39m, in \u001b[36m_IterableDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m         data.append(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset_iter\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m     35\u001b[39m         \u001b[38;5;28mself\u001b[39m.ended = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smrt-foundation/smrt_foundation/dataset.py:165\u001b[39m, in \u001b[36mLegacyMethylDataset.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices:\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# array cast\u001b[39;00m\n\u001b[32m    162\u001b[39m     df = pl.from_arrow(pqf.read_row_group(i)).with_columns([\n\u001b[32m    163\u001b[39m         pl.col(c).list.to_array(\u001b[38;5;28mself\u001b[39m.context) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.kin_feats\n\u001b[32m    164\u001b[39m     ])\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_batch(df)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smrt-foundation/smrt_foundation/dataset.py:92\u001b[39m, in \u001b[36mLegacyMethylDataset._process_batch\u001b[39m\u001b[34m(self, df)\u001b[39m\n\u001b[32m     90\u001b[39m     vals = (np.log(vals + \u001b[32m1\u001b[39m) - \u001b[38;5;28mself\u001b[39m.means[k]) / \u001b[38;5;28mself\u001b[39m.stds[k]\n\u001b[32m     91\u001b[39m     kin_list.append(vals)\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m kin_t = torch.tensor(np.stack(kin_list, axis=\u001b[32m1\u001b[39m), dtype=\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# mask, labels, etc\u001b[39;00m\n\u001b[32m     95\u001b[39m mask = torch.zeros((seq_t.shape[\u001b[32m0\u001b[39m], seq_t.shape[\u001b[32m1\u001b[39m], \u001b[32m1\u001b[39m), dtype=torch.float)\n",
      "\u001b[31mTypeError\u001b[39m: 'torch.dtype' object is not callable"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from smrt_foundation.probe import SingleIdxProbe\n",
    "EPOCHS = 5\n",
    "DEVICE = torch.device('cuda')\n",
    "encoder_clone = copy.deepcopy(model.encoder)\n",
    "# Fixed: used DEVICE instead of device\n",
    "probe = SingleIdxProbe(encoder_clone, freeze_encoder=False).to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': probe.encoder.parameters(), 'lr': 5e-7},\n",
    "    {'params': probe.head.parameters(), 'lr': 3e-5}\n",
    "])\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    probe.train()\n",
    "    running_loss = 0.0\n",
    "    for i, batch in enumerate(tqdm(methyl_train_dl)):\n",
    "        inputs = batch['data'].to(DEVICE)\n",
    "        labels = batch['label'].to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = probe(inputs)\n",
    "        loss = criterion(logits, labels.unsqueeze(1).to(torch.float32))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if (i + 1) % 100 == 0:\n",
    "            loss_history.append(running_loss / 100)\n",
    "            running_loss = 0.0\n",
    "\n",
    "    probe.eval()\n",
    "    sample_count = 0\n",
    "    sample_correct = 0\n",
    "    # Added torch.no_grad() for validation efficiency\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(methyl_val_dl):\n",
    "            inputs = batch['data'].to(DEVICE)\n",
    "            labels = batch['label'].to(DEVICE)\n",
    "\n",
    "            logits = probe(inputs)\n",
    "            preds = logits > 0\n",
    "            correct = labels == preds.squeeze(-1)\n",
    "            sample_count += correct.shape[0]\n",
    "            sample_correct += correct.sum()\n",
    "    \n",
    "    print(f\"epoch val top1_acc: {sample_correct/sample_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f645b90-4db9-472c-906c-1817d70c6f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0df4050-3651-42c7-8fb9-a4833b505557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
