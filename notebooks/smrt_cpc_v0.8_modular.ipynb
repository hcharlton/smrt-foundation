{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0fe52ef-a308-4ff5-9f17-a93faf23df29",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0accf8b-9ab6-4ef7-932d-f1cdc04a222e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2d5403d-2b9c-4627-8c60-a7dd241743ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30568b95-93f0-4adf-b091-67274e9fae37",
   "metadata": {},
   "source": [
    "## Load local module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65096da3-e095-412c-a7dd-5c67d58f0020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(\"/dcai/users/chache/smrt-foundation\")\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "device=torch.device('cuda')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00d55fc-4ed8-45b9-a84a-d71adc8ab250",
   "metadata": {},
   "source": [
    "## Optional copy step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1a560f2-68ce-4e7f-bf15-aa5ea0e0b00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16G\t../data/01_processed/ssl_sets/ob007_test.memmap/\n",
      "'./shard_00028.npy' -> '/tmp/shard_00028.npy'\n",
      "'./shard_00021.npy' -> '/tmp/shard_00021.npy'\n",
      "'./shard_00026.npy' -> '/tmp/shard_00026.npy'\n",
      "'./shard_00013.npy' -> '/tmp/shard_00013.npy'\n",
      "'./shard_00014.npy' -> '/tmp/shard_00014.npy'\n",
      "'./shard_00005.npy' -> '/tmp/shard_00005.npy'\n",
      "'./shard_00002.npy' -> '/tmp/shard_00002.npy'\n",
      "'./shard_00030.npy' -> '/tmp/shard_00030.npy'\n",
      "'./shard_00015.npy' -> '/tmp/shard_00015.npy'\n",
      "'./shard_00012.npy' -> '/tmp/shard_00012.npy'\n",
      "'./shard_00027.npy' -> '/tmp/shard_00027.npy'\n",
      "'./shard_00020.npy' -> '/tmp/shard_00020.npy'\n",
      "'./shard_00029.npy' -> '/tmp/shard_00029.npy'\n",
      "'./shard_00031.npy' -> '/tmp/shard_00031.npy'\n",
      "'./shard_00003.npy' -> '/tmp/shard_00003.npy'\n",
      "'./shard_00004.npy' -> '/tmp/shard_00004.npy'\n",
      "'./shard_00007.npy' -> '/tmp/shard_00007.npy'\n",
      "'./shard_00000.npy' -> '/tmp/shard_00000.npy'\n",
      "'./shard_00009.npy' -> '/tmp/shard_00009.npy'\n",
      "'./shard_00018.npy' -> '/tmp/shard_00018.npy'\n",
      "'./shard_00011.npy' -> '/tmp/shard_00011.npy'\n",
      "'./shard_00016.npy' -> '/tmp/shard_00016.npy'\n",
      "'./shard_00023.npy' -> '/tmp/shard_00023.npy'\n",
      "'./shard_00024.npy' -> '/tmp/shard_00024.npy'\n",
      "'./shard_00008.npy' -> '/tmp/shard_00008.npy'\n",
      "'./shard_00001.npy' -> '/tmp/shard_00001.npy'\n",
      "'./shard_00006.npy' -> '/tmp/shard_00006.npy'\n",
      "'./shard_00025.npy' -> '/tmp/shard_00025.npy'\n",
      "'./shard_00022.npy' -> '/tmp/shard_00022.npy'\n",
      "'./shard_00017.npy' -> '/tmp/shard_00017.npy'\n",
      "'./shard_00010.npy' -> '/tmp/shard_00010.npy'\n",
      "'./shard_00019.npy' -> '/tmp/shard_00019.npy'\n",
      "\n",
      "real\t0m0.688s\n",
      "user\t0m0.025s\n",
      "sys\t0m10.235s\n",
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "tmpfs          1008G   41G  967G   5% /tmp\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! du -h ../data/01_processed/ssl_sets/ob007_test.memmap/\n",
    "! cd ../data/01_processed/ssl_sets/ob007_test.memmap/ && time find  -type f -name '*.npy' | xargs -P16 -IX cp -v X $TMPDIR/ \n",
    "! df -h ${TMPDIR:-/tmp}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35721f8-49e5-4530-af0c-56c1592881ac",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d5594d9-8412-41c9-8e30-1f5855ad109f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "mmap length is greater than file size",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m B = \u001b[32m64\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ssl_ds = ShardedMemmapDataset(\"../data/01_processed/ssl_sets/ob007_test.memmap/\")\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m ssl_ds = \u001b[43mShardedMemmapDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/tmp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m ssl_dl = DataLoader(ssl_ds, batch_size=B, num_workers=\u001b[32m8\u001b[39m, pin_memory=\u001b[38;5;28;01mTrue\u001b[39;00m, prefetch_factor=\u001b[32m4\u001b[39m, shuffle=\u001b[32m2\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smrt-foundation/smrt_foundation/dataset.py:19\u001b[39m, in \u001b[36mShardedMemmapDataset.__init__\u001b[39m\u001b[34m(self, data_dir, cache_size, limit)\u001b[39m\n\u001b[32m     17\u001b[39m first_shard = np.load(\u001b[38;5;28mself\u001b[39m.shard_paths[\u001b[32m0\u001b[39m], mmap_mode=\u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28mself\u001b[39m.shard_size = first_shard.shape[\u001b[32m0\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m last_shard = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshard_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmap_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mself\u001b[39m.full_len = ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.shard_paths) - \u001b[32m1\u001b[39m) * \u001b[38;5;28mself\u001b[39m.shard_size) + last_shard.shape[\u001b[32m0\u001b[39m]\n\u001b[32m     21\u001b[39m \u001b[38;5;28mself\u001b[39m.len = \u001b[38;5;28mself\u001b[39m.full_len \u001b[38;5;28;01mif\u001b[39;00m limit == \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m.full_len, limit)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/numpy/lib/_npyio_impl.py:485\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    483\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m allow_pickle:\n\u001b[32m    484\u001b[39m         max_header_size = \u001b[32m2\u001b[39m**\u001b[32m64\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopen_memmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmmap_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m.read_array(fid, allow_pickle=allow_pickle,\n\u001b[32m    489\u001b[39m                              pickle_kwargs=pickle_kwargs,\n\u001b[32m    490\u001b[39m                              max_header_size=max_header_size)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/numpy/lib/format.py:972\u001b[39m, in \u001b[36mopen_memmap\u001b[39m\u001b[34m(filename, mode, dtype, shape, fortran_order, version, max_header_size)\u001b[39m\n\u001b[32m    969\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m'\u001b[39m\u001b[33mw+\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    970\u001b[39m     mode = \u001b[33m'\u001b[39m\u001b[33mr+\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m972\u001b[39m marray = \u001b[43mnumpy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmemmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m marray\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/numpy/_core/memmap.py:280\u001b[39m, in \u001b[36mmemmap.__new__\u001b[39m\u001b[34m(subtype, filename, dtype, mode, offset, shape, order)\u001b[39m\n\u001b[32m    278\u001b[39m \u001b[38;5;28mbytes\u001b[39m -= start\n\u001b[32m    279\u001b[39m array_offset = offset - start\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m mm = \u001b[43mmmap\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfileno\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccess\u001b[49m\u001b[43m=\u001b[49m\u001b[43macc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[38;5;28mself\u001b[39m = ndarray.\u001b[34m__new__\u001b[39m(subtype, shape, dtype=descr, buffer=mm,\n\u001b[32m    283\u001b[39m                        offset=array_offset, order=order)\n\u001b[32m    284\u001b[39m \u001b[38;5;28mself\u001b[39m._mmap = mm\n",
      "\u001b[31mValueError\u001b[39m: mmap length is greater than file size"
     ]
    }
   ],
   "source": [
    "from smrt_foundation.dataset import ShardedMemmapDataset\n",
    "B = 64\n",
    "# ssl_ds = ShardedMemmapDataset(\"../data/01_processed/ssl_sets/ob007_test.memmap/\")\n",
    "ssl_ds = ShardedMemmapDataset(\"/tmp\")\n",
    "ssl_dl = DataLoader(ssl_ds, batch_size=B, num_workers=8, pin_memory=True, prefetch_factor=4, shuffle=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61673259-d529-46d2-b571-a8e961e13312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.9404, -0.7085,  0.0000],\n",
       "        [ 0.0000,  0.4214, -0.4341,  0.0000],\n",
       "        [ 3.0000, -1.3145, -0.5669,  0.0000],\n",
       "        [ 0.0000,  0.5586, -0.1920,  0.0000],\n",
       "        [ 0.0000,  0.7993, -1.0254,  0.0000],\n",
       "        [ 3.0000, -0.4849, -0.8608,  0.0000],\n",
       "        [ 0.0000,  1.3965,  0.0246,  0.0000],\n",
       "        [ 0.0000,  0.0383, -0.4341,  0.0000],\n",
       "        [ 3.0000,  0.0997, -0.5669,  0.0000],\n",
       "        [ 2.0000,  2.0684,  0.7886,  0.0000]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(ssl_dl))\n",
    "batch[0,0:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2b85779-3d4c-4f2b-8629-6c42e22f4ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7976/7976 [00:14<00:00, 557.40it/s]\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(ssl_dl):\n",
    "    x=batch.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fb7356-c964-4582-aab9-1058776ba962",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67b1c29a-16f5-4aad-b7bd-b14ac1e088da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable parameters: 2.08m\n"
     ]
    }
   ],
   "source": [
    "from smrt_foundation.model import Smrt2Vec\n",
    "from smrt_foundation.loss import InfoNCE\n",
    "model = Smrt2Vec().to(device)\n",
    "model.train()\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"trainable parameters: {round(total_params/1e6,2)}m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bce11e6-a0dd-4f03-be50-48bfd51acdbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.7200, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = InfoNCE()\n",
    "c_proj, targets, mask = model(batch.to(device))\n",
    "loss(c_proj, targets, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda94886-4b85-4265-8c26-382885dc8704",
   "metadata": {},
   "source": [
    "# Pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf3b37aa-90b9-459d-9b22-5c82f20e802b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb 16 15:15:20 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.126.09             Driver Version: 580.126.09     CUDA Version: 13.1     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA H100 80GB HBM3          On  |   00000000:1B:00.0 Off |                    0 |\n",
      "| N/A   31C    P0            125W /  700W |    8273MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA H100 80GB HBM3          On  |   00000000:43:00.0 Off |                    0 |\n",
      "| N/A   30C    P0             71W /  700W |       4MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA H100 80GB HBM3          On  |   00000000:52:00.0 Off |                    0 |\n",
      "| N/A   32C    P0             71W /  700W |       4MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA H100 80GB HBM3          On  |   00000000:61:00.0 Off |                    0 |\n",
      "| N/A   32C    P0             68W /  700W |       4MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   4  NVIDIA H100 80GB HBM3          On  |   00000000:9D:00.0 Off |                    0 |\n",
      "| N/A   29C    P0             70W /  700W |       4MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   5  NVIDIA H100 80GB HBM3          On  |   00000000:C3:00.0 Off |                    0 |\n",
      "| N/A   30C    P0             69W /  700W |       4MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   6  NVIDIA H100 80GB HBM3          On  |   00000000:D1:00.0 Off |                    0 |\n",
      "| N/A   32C    P0             68W /  700W |       4MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   7  NVIDIA H100 80GB HBM3          On  |   00000000:DF:00.0 Off |                    0 |\n",
      "| N/A   31C    P0             69W /  700W |       4MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A         3065469      C   /usr/bin/python                        8264MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ee6ec80-8ce8-4258-acae-72e849b0a74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if torch.cuda.device_count() > 1:\n",
    "#    print(f\"Using {torch.cuda.device_count()} GPUs via DataParallel\")\n",
    "#    model = nn.DataParallel(Smrt2Vec())\n",
    "#    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "664fb7e8-b12a-4ad3-be30-151b91e00419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4:  11%|█         | 865/7976 [00:45<06:16, 18.87it/s, loss=7.2108, lr=0.000348]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m batch = batch.to(device, non_blocking=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.amp.autocast(device_type=\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m, dtype=torch.bfloat16):\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     c_proj, targets, mask_idx = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     loss = criterion(c_proj, targets, mask_idx)\n\u001b[32m     24\u001b[39m optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1783\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1783\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1794\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1790\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1791\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1792\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1793\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1794\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1796\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1797\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smrt-foundation/smrt_foundation/model.py:341\u001b[39m, in \u001b[36mSmrt2Vec.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    339\u001b[39m \u001b[38;5;66;03m# mask indices for loss\u001b[39;00m\n\u001b[32m    340\u001b[39m z_masked, z_masked_bool = \u001b[38;5;28mself\u001b[39m.apply_mask(z, z_pad)\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m z_masked_pe = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m.add_pe(z_masked)\n\u001b[32m    342\u001b[39m \u001b[38;5;66;03m# run through transformer\u001b[39;00m\n\u001b[32m    343\u001b[39m c = \u001b[38;5;28mself\u001b[39m.encoder.forward_transformer(z_masked_pe, z_pad)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1959\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1954\u001b[39m         \u001b[38;5;28mself\u001b[39m._backward_pre_hooks = OrderedDict()\n\u001b[32m   1956\u001b[39m \u001b[38;5;66;03m# It is crucial that the return type is not annotated as `Any`, otherwise type checking\u001b[39;00m\n\u001b[32m   1957\u001b[39m \u001b[38;5;66;03m# on `torch.nn.Module` and all its subclasses is largely disabled as a result. See:\u001b[39;00m\n\u001b[32m   1958\u001b[39m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/pull/115074\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1959\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) -> Union[Tensor, \u001b[33m\"\u001b[39m\u001b[33mModule\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1960\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m_parameters\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m:\n\u001b[32m   1961\u001b[39m         _parameters = \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33m_parameters\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.02)\n",
    "criterion = InfoNCE(temperature=0.1).to(device)\n",
    "EPOCHS = 4\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=6e-4,\n",
    "    total_steps=len(ssl_dl) * EPOCHS,\n",
    "    pct_start=0.05\n",
    ")\n",
    "    \n",
    "model.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    progress_bar = tqdm(ssl_dl, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "\n",
    "    for i, batch in enumerate(progress_bar):\n",
    "        batch = batch.to(device, non_blocking=True)\n",
    "\n",
    "        with torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "            c_proj, targets, mask_idx = model(batch)\n",
    "            loss = criterion(c_proj, targets, mask_idx)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            progress_bar.set_postfix(\n",
    "                loss=f\"{loss.item():.4f}\",\n",
    "                lr=f\"{scheduler.get_last_lr()[0]:.6f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfe6610-83a1-4ef8-877c-baff1c481044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), '../models/smrt2vec_8epoch.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e135487c-f327-4650-a52a-2327239962c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smrt_foundation.dataset import LegacyMethylDataset, compute_log_normalization_stats\n",
    "import polars as pl\n",
    "TRAIN_PATH = '../data/01_processed/val_sets/pacbio_standard_train.parquet'\n",
    "VAL_PATH =  '../data/01_processed/val_sets/pacbio_standard_test.parquet'\n",
    "KINETICS_FEATURES = ['fi', 'fp', 'ri', 'rp']\n",
    "\n",
    "df = pl.read_parquet(TRAIN_PATH).head(1_000_000)\n",
    "train_means, train_stds = compute_log_normalization_stats(df, KINETICS_FEATURES)\n",
    "\n",
    "methyl_train_ds = LegacyMethylDataset(TRAIN_PATH, train_means, train_stds, context=32, restrict_row_groups=5)\n",
    "methyl_train_dl = DataLoader(methyl_train_ds,\n",
    "                             # num_workers=8,\n",
    "                             batch_size=256,\n",
    "                             drop_last=True,\n",
    "                             persistent_workers=False,\n",
    "                             # prefetch_factor=5\n",
    "                            )\n",
    "\n",
    "methyl_val_ds = LegacyMethylDataset(VAL_PATH,\n",
    "                                      means=train_means,\n",
    "                                      stds=train_stds,\n",
    "                                      context=32,\n",
    "                                      restrict_row_groups=5)\n",
    "methyl_val_dl = DataLoader(methyl_val_ds,\n",
    "                        batch_size=256,\n",
    "                        drop_last=True,\n",
    "                        persistent_workers=False,\n",
    "                        prefetch_factor=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aefd3f-eeac-47d6-9ab5-13af7dd648e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7ce833-3e47-4b97-b177-6913c9ef37c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from smrt_foundation.probe import SingleIdxProbe\n",
    "EPOCHS = 5\n",
    "DEVICE = torch.device('cuda')\n",
    "encoder_clone = copy.deepcopy(model.encoder)\n",
    "# Fixed: used DEVICE instead of device\n",
    "probe = SingleIdxProbe(encoder_clone, freeze_encoder=False).to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': probe.encoder.parameters(), 'lr': 5e-7},\n",
    "    {'params': probe.head.parameters(), 'lr': 3e-5}\n",
    "])\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    probe.train()\n",
    "    running_loss = 0.0\n",
    "    for i, batch in enumerate(tqdm(methyl_train_dl)):\n",
    "        inputs = batch['data'].to(DEVICE)\n",
    "        labels = batch['label'].to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = probe(inputs)\n",
    "        loss = criterion(logits, labels.unsqueeze(1).to(torch.float32))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if (i + 1) % 100 == 0:\n",
    "            loss_history.append(running_loss / 100)\n",
    "            running_loss = 0.0\n",
    "\n",
    "    probe.eval()\n",
    "    sample_count = 0\n",
    "    sample_correct = 0\n",
    "    # Added torch.no_grad() for validation efficiency\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(methyl_val_dl):\n",
    "            inputs = batch['data'].to(DEVICE)\n",
    "            labels = batch['label'].to(DEVICE)\n",
    "\n",
    "            logits = probe(inputs)\n",
    "            preds = logits > 0\n",
    "            correct = labels == preds.squeeze(-1)\n",
    "            sample_count += correct.shape[0]\n",
    "            sample_correct += correct.sum()\n",
    "    \n",
    "    print(f\"epoch val top1_acc: {sample_correct/sample_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f645b90-4db9-472c-906c-1817d70c6f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0df4050-3651-42c7-8fb9-a4833b505557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
